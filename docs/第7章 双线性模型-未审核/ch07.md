# 第7章 双线性模型

## 习题1

以下关于双线性模型的说法，不正确的是：

&emsp; A. 双线性模型考虑了特征之间的关联，比线性模型建模能力更强。  
&emsp; B. 在因子分解机中，因为引入了特征的乘积，只有特征 $x_i$ 与 $x_j$ 都不为零时才能更新参数 $w_{ij}$ 。   
&emsp; C. 可以通过重新设置参数，把因子分解机中的常数项和一次项都合并到二次项里，得到更一般的表达式。  
&emsp; D. 在矩阵分解中，最优的特征数量$d$是超参数，不能通过公式推导出来。

**解答**

&emsp;&emsp; **答案：C**  
  
&emsp;&emsp; A. 正确。双线性模型通过引入特征之间的交互项，能够捕捉特征间的关联性，能对更加复杂的场景进行建模，也可以通过设置参数退化到线性模型，因此比单纯的线性模型具有更强的建模能力。   
&emsp;&emsp; B. 正确。在因子分解机中，特征交互项 $\langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j$ 只有在 $x_i$ 和 $x_j$ 都不为零时才会产生影响，此时才能通过梯度更新相应的参数 $w_{ij}$ 。  
&emsp;&emsp; C. 错误。因子分解机的表达式为 $y = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n\sum_{j=i+1}^n \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j$ ，其中包含常数项、一次项和二次项。无法通过简单地重新设置参数将常数项和一次项都合并到二次项中，因为当某些特征为零时，对应的二次项也会为零，而一次项和常数项仍然存在。  
&emsp;&emsp; D. 正确。在矩阵分解中，隐因子的维度$d$是需要通过交叉验证等方法确定的超参数，无法通过理论公式直接推导出最优值。或可以使用启发式算法来选择。

## 习题2

以下哪一个模型不是关于双线性模型：  
&emsp; A. $f(\theta_1, \theta_2) = \theta_1 \theta_2$  
&emsp; B. $f(\theta_1, \theta_2) = \langle\theta_1, \theta_2\rangle$  
&emsp; C. $f(\theta_1, \theta_2) = 0$  
&emsp; D. $f(\theta_1, \theta_2) = e^{\theta_1} e^{\theta_2}$  


**解答**

&emsp;&emsp;**答案：D**    
  
&emsp;&emsp; A. 正确。是乘积（相互作用）。  
&emsp;&emsp; B. 正确。是内积（相似性）。  
&emsp;&emsp; C. 正确。$f(\theta_1, \theta_2) = 0$ 是常数函数，可以视为特殊情况的双线性函数（系数都为0）。它对任意变量都是线性的。  
&emsp;&emsp; D. 错误。$f(\theta_1, \theta_2) = e^{\theta_1} e^{\theta_2}$ 不是双线性的。  
&emsp;&emsp; 验证选项D：  
&emsp;&emsp; 对于双线性函数，应满足 $f(\theta_1+t, \theta_2) = f(\theta_1, \theta_2) + f(t, \theta_2)$  
&emsp;&emsp; 但 $f(\theta_1+t, \theta_2) = e^{\theta_1+t} e^{\theta_2} = e^{\theta_1} e^{t} e^{\theta_2}$  
&emsp;&emsp; 而 $f(\theta_1, \theta_2) + f(t, \theta_2) = e^{\theta_1} e^{\theta_2} + e^{t} e^{\theta_2} = e^{\theta_2}(e^{\theta_1} + e^{t})$  
&emsp;&emsp; 显然 $e^{\theta_1} e^{t} e^{\theta_2} \neq e^{\theta_2}(e^{\theta_1} + e^{t})$ ，因此不满足双线性性质。

## 习题3

关于多域独热编码，思考其相比于如下编码方式的优势：针对每一个域，依次把其中的离散取值以自然数（以 0 开始）作为编码，在编码后每个域就对应一个自然数。例如图 7-3 中产地上海对应为 1，深圳对应为 3，生产月份 2 月对应为 1，12 月对应为 11，食品种类乳制品对应为 0，图中的整个编码向量为 (1, 2, …, 0)。

**解答**

&emsp;&emsp;多域独热编码相比于自然数编码有以下优势：  
  
- 避免数值影响。数值大小在计算中可能会对模型的影响不一样，独热编码可以统一为二进制。
- 避免不必要的相关性。自然数编码数字之间模型可能会认为特征会存在相关性，不像二进制直接划分，1-9的自然数模型可能会认为不同的数字也会产生相关性。
- 处理缺失值。如果某个域缺失了，自然数编码该分配什么编码呢？独热编码会分配一个全零向量。
- 更好地找到特征的关系。独热编码进行交叉乘积可以明显地得到特征之间的关系。

## 习题4

试修改 MF 的 `pred(self, user_id, item_id)` 函数，在模型预测中加入全局打分偏置、用户打分偏置和物品打分偏置，类似 `FM`模型中的常数项部分，观察模型拟合性能指标的变化。

**解答**

&emsp;&emsp; 加入偏置可以获得更好的模型拟合，提高模型的泛化能力  
&emsp;&emsp; 实验证明，加入偏置项使用原超参数大小直接梯度爆炸了，调整超参数后依然过拟合  


```python
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm # 进度条工具

data = np.loadtxt('movielens_100k.csv', delimiter=',', dtype=int)
print('数据集大小：', len(data))
# 用户和电影都是从1开始编号的，我们将其转化为从0开始
data[:, :2] = data[:, :2] - 1

# 计算用户和电影数量
users = set()
items = set()
for i, j, k in data:
    users.add(i)
    items.add(j)
user_num = len(users)
item_num = len(items)
print(f'用户数：{user_num}，电影数：{item_num}')

# 设置随机种子，划分训练集与测试集
np.random.seed(0)

ratio = 0.8
split = int(len(data) * ratio)
np.random.shuffle(data)
train = data[:split]
test = data[split:]

# 统计训练集中每个用户和电影出现的数量，作为正则化的权重
user_cnt = np.bincount(train[:, 0], minlength=user_num)
item_cnt = np.bincount(train[:, 1], minlength=item_num)
print(user_cnt[:10])
print(item_cnt[:10])

# ----------------------------------------
# 添加全局打分偏置、用户打分偏置和电影打分偏置
# 初始化全局打分偏置、用户打分偏置和电影打分偏置
global_bias = np.mean(train[:, 2])
user_biases = np.zeros(user_num)


item_biases = np.zeros(item_num)

# 计算每个用户和电影的平均打分
user_means = np.zeros(user_num)
item_means = np.zeros(item_num)
user_cnt = np.bincount(train[:, 0], minlength=user_num)
item_cnt = np.bincount(train[:, 1], minlength=item_num)
for i, j, k in train:
    user_means[i] += k
    item_means[j] += k
user_means = np.divide(user_means, user_cnt, out=np.zeros_like(user_means), where=user_cnt!=0)
item_means = np.divide(item_means, item_cnt, out=np.zeros_like(item_means), where=item_cnt!=0)

# 计算用户和电影的打分偏置
user_biases = user_means - global_bias
item_biases = item_means - global_bias
# ----------------------------------------

# 用户和电影的编号要作为下标，必须保存为整数
user_train, user_test = train[:, 0], test[:, 0]
item_train, item_test = train[:, 1], test[:, 1]
y_train, y_test = train[:, 2], test[:, 2]

```

    数据集大小： 100000
    用户数：943，电影数：1682
    [215  47  42  19 139 170 320  47  18 156]
    [371 109  70 172  70  21 308 158 240  68]
    


```python
class MF:

    def __init__(self, N, M, d):
        # N是用户数量，M是电影数量，d是特征维度
        # 定义模型参数
        self.user_params = np.ones((N, d))
        self.item_params = np.ones((M, d))
        self.global_bias = 0
        self.user_biases = np.zeros(N)
        self.item_biases = np.zeros(M)

    def pred(self, user_id, item_id):
        # 预测用户user_id对电影item_id的打分
        # 获得用户偏好和电影特征
        user_param = self.user_params[user_id]
        item_param = self.item_params[item_id]
        # 计算用户和电影的交互作用
        interaction = np.sum(user_param * item_param, axis=1)
        # 加入全局打分偏置、用户打分偏置和电影打分偏置
        global_bias = self.global_bias
        user_bias = self.user_biases[user_id]
        item_bias = self.item_biases[item_id]
        rating_pred = global_bias + user_bias + item_bias + interaction
        
        return rating_pred

    def update(self, user_grad, item_grad, lr):
        # 根据参数的梯度更新参数
        self.user_params -= lr * user_grad
        self.item_params -= lr * item_grad
```


```python
def train(model, learning_rate, lbd, max_training_step, batch_size):
    train_losses = []
    test_losses = []
    batch_num = int(np.ceil(len(user_train) / batch_size))
    with tqdm(range(max_training_step * batch_num)) as pbar:
        for epoch in range(max_training_step):
            # 随机梯度下降
            train_rmse = 0
            for i in range(batch_num):
                # 获取当前批量
                st = i * batch_size
                ed = min(len(user_train), st + batch_size)
                user_batch = user_train[st: ed]
                item_batch = item_train[st: ed]
                y_batch = y_train[st: ed]
                # 计算模型预测
                y_pred = model.pred(user_batch, item_batch)
                # 计算梯度
                P = model.user_params
                Q = model.item_params
                errs = y_batch - y_pred
                P_grad = np.zeros_like(P)
                Q_grad = np.zeros_like(Q)
                # 加入偏置的梯度
                global_bias_grad = 0
                user_bias_grad = np.zeros_like(model.user_biases)
                item_bias_grad = np.zeros_like(model.item_biases) 

                for user, item, err in zip(user_batch, item_batch, errs):
                    P_grad[user] = P_grad[user] - err * Q[item] + lbd * P[user]
                    Q_grad[item] = Q_grad[item] - err * P[user] + lbd * Q[item]
                    interaction = np.sum(P[user] * Q[item])
                    global_bias_grad -= err
                    user_bias_grad[user] -= err
                    item_bias_grad[item] -= err
                # 更新全局打分偏置
                model.global_bias += learning_rate * global_bias_grad / len(user_batch)
                # 更新用户打分偏置
                model.user_biases += learning_rate * user_bias_grad / len(user_batch)
                # 更新电影打分偏置
                model.item_biases += learning_rate * item_bias_grad / len(user_batch)
                
                model.update(P_grad / len(user_batch), Q_grad / len(user_batch), learning_rate)
                
                train_rmse += np.mean(errs ** 2)
                # 更新进度条
                pbar.set_postfix({
                    'Epoch': epoch,
                    'Train RMSE': f'{np.sqrt(train_rmse / (i + 1)):.4f}',
                    'Test RMSE': f'{test_losses[-1]:.4f}' if test_losses else None
                })
                pbar.update(1)

            # 计算测试集上的RMSE
            train_rmse = np.sqrt(train_rmse / len(user_train))
            train_losses.append(train_rmse)
            y_test_pred = model.pred(user_test, item_test)
            test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))
            test_losses.append(test_rmse)

    return train_losses, test_losses
```


```python
# 超参数
feature_num = 128 # 特征数
learning_rate = 0.01 # 学习率
lbd = 1e-1 # 正则化强度
max_training_step = 10
batch_size = 64 # 批量大小

# 建立模型
model = MF(user_num, item_num, feature_num)
# 训练部分
train_losses, test_losses = train(model, learning_rate, lbd,
    max_training_step, batch_size)

plt.figure()
x = np.arange(max_training_step) + 1
plt.plot(x, train_losses, color='blue', label='train loss')
plt.plot(x, test_losses, color='red', ls='--', label='test loss')
plt.xlabel('Epoch')
plt.ylabel('RMSE')
plt.legend()
plt.show()
```

    100%|██████████| 12500/12500 [00:41<00:00, 301.26it/s, Epoch=9, Train RMSE=1.8535, Test RMSE=154.5553] 
    


    
![png](images/ch07_20_1.png)
    



```python
y_test_pred = model.pred(user_test, item_test)
print(y_test_pred[:10]) # 把张量转换为numpy数组
print(y_test[:10])
```

    [1.31120225 4.556555   2.76502584 4.78647637 5.78246472 3.35982054
     4.1325364  2.84627579 2.25076913 3.12091915]
    [2 4 4 4 5 2 3 1 4 4]
    

## 习题5

试基于本章的`MF`代码，调试不同的超参数，包括 $k$ 和 $\lambda$ ，关注训练集和测试集的性能指标的改变，根据训练和测试的性能曲线，判定哪些超参数导致过拟合。

**解答**


```python
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm # 进度条工具

data = np.loadtxt('movielens_100k.csv', delimiter=',', dtype=int)
print('数据集大小：', len(data))
# 用户和电影都是从1开始编号的，我们将其转化为从0开始
data[:, :2] = data[:, :2] - 1

# 计算用户和电影数量
users = set()
items = set()
for i, j, k in data:
    users.add(i)
    items.add(j)
user_num = len(users)
item_num = len(items)
print(f'用户数：{user_num}，电影数：{item_num}')

# 设置随机种子，划分训练集与测试集
np.random.seed(0)

ratio = 0.8
split = int(len(data) * ratio)
np.random.shuffle(data)
train = data[:split]
test = data[split:]

# 统计训练集中每个用户和电影出现的数量，作为正则化的权重
user_cnt = np.bincount(train[:, 0], minlength=user_num)
item_cnt = np.bincount(train[:, 1], minlength=item_num)
print(user_cnt[:10])
print(item_cnt[:10])

# 用户和电影的编号要作为下标，必须保存为整数
user_train, user_test = train[:, 0], test[:, 0]
item_train, item_test = train[:, 1], test[:, 1]
y_train, y_test = train[:, 2], test[:, 2]

class MF:
    
    def __init__(self, N, M, d):
        # N是用户数量，M是电影数量，d是特征维度
        # 定义模型参数
        self.user_params = np.ones((N, d))
        self.item_params = np.ones((M, d))
        
    def pred(self, user_id, item_id):
        # 预测用户user_id对电影item_id的打分
        # 获得用户偏好和电影特征
        user_param = self.user_params[user_id]
        item_param = self.item_params[item_id]
        # 返回预测的评分
        if isinstance(user_id, np.ndarray) and len(user_id) > 1:
            # 批量预测
            rating_pred = np.sum(user_param * item_param, axis=1)
        else:
            # 单个预测
            rating_pred = np.sum(user_param * item_param)
            
        return rating_pred

    def update(self, user_grad, item_grad, lr):
        # 根据参数的梯度更新参数
        self.user_params -= lr * user_grad
        self.item_params -= lr * item_grad

        

```

    数据集大小： 100000
    用户数：943，电影数：1682
    [215  47  42  19 139 170 320  47  18 156]
    [371 109  70 172  70  21 308 158 240  68]
    


```python
def train(model, learning_rate, lbd, max_training_step, batch_size):
    train_losses = []
    test_losses = []
    batch_num = int(np.ceil(len(user_train) / batch_size))
    with tqdm(range(max_training_step * batch_num)) as pbar:
        for epoch in range(max_training_step):
            # 随机梯度下降
            train_rmse = 0
            for i in range(batch_num):
                # 获取当前批量
                st = i * batch_size
                ed = min(len(user_train), st + batch_size)
                user_batch = user_train[st: ed]
                item_batch = item_train[st: ed]
                y_batch = y_train[st: ed]
                # 计算模型预测
                y_pred = model.pred(user_batch, item_batch)
                # 计算梯度
                P = model.user_params
                Q = model.item_params
                errs = y_batch - y_pred
                P_grad = np.zeros_like(P)
                Q_grad = np.zeros_like(Q)
                for user, item, err in zip(user_batch, item_batch, errs):
                    P_grad[user] = P_grad[user] - err * Q[item] + lbd * P[user]
                    Q_grad[item] = Q_grad[item] - err * P[user] + lbd * Q[item]
                model.update(P_grad / len(user_batch), Q_grad / len(user_batch), learning_rate)
                
                train_rmse += np.mean(errs ** 2)
                # 更新进度条
                pbar.set_postfix({
                    'Epoch': epoch,
                    'Train RMSE': f'{np.sqrt(train_rmse / (i + 1)):.4f}',
                    'Test RMSE': f'{test_losses[-1]:.4f}' if test_losses else None
                })
                pbar.update(1)

            # 计算 RMSE 损失
            train_rmse = np.sqrt(train_rmse / len(user_train))
            train_losses.append(train_rmse)
            y_test_pred = model.pred(user_test, item_test)
            test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))
            test_losses.append(test_rmse)
    
    return train_losses, test_losses
```


```python
def train(model, learning_rate, lbd, max_training_step, batch_size):
    train_losses = []
    test_losses = []
    batch_num = int(np.ceil(len(user_train) / batch_size))
    with tqdm(range(max_training_step * batch_num)) as pbar:
        for epoch in range(max_training_step):
            # 随机打乱训练数据的顺序
            indices = np.random.permutation(len(user_train))
            shuffled_user_train = user_train[indices]
            shuffled_item_train = item_train[indices]
            shuffled_y_train = y_train[indices]
            
            # 随机梯度下降
            epoch_train_rmse = 0
            for i in range(batch_num):
                # 获取当前批量
                st = i * batch_size
                ed = min(len(shuffled_user_train), st + batch_size)
                # 确保当前批次有足够的数据
                if ed <= st:
                    continue
                    
                user_batch = shuffled_user_train[st:ed]
                item_batch = shuffled_item_train[st:ed]
                y_batch = shuffled_y_train[st:ed]
                
                # 计算模型预测
                y_pred = model.pred(user_batch, item_batch)
                
                # 确保形状匹配
                if len(y_pred) != len(y_batch):
                    raise ValueError(f"Prediction shape {len(y_pred)} doesn't match target shape {len(y_batch)}")
                    
                # 计算梯度
                P = model.user_params
                Q = model.item_params
                errs = y_batch - y_pred
                P_grad = np.zeros_like(P)
                Q_grad = np.zeros_like(Q)
                
                for user, item, err in zip(user_batch, item_batch, errs):
                    P_grad[user] = P_grad[user] - err * Q[item] + lbd * P[user] 
                    Q_grad[item] = Q_grad[item] - err * P[user] + lbd * Q[item]
                    
                model.update(P_grad / len(user_batch), Q_grad / len(user_batch), learning_rate)
                
                batch_rmse = np.sqrt(np.mean(errs ** 2))
                epoch_train_rmse += batch_rmse * len(user_batch)
                
                # 更新进度条
                pbar.set_postfix({
                    'Epoch': epoch,
                    'Train RMSE': f'{batch_rmse:.4f}',
                    'Test RMSE': f'{test_losses[-1]:.4f}' if test_losses else 'N/A'
                })
                pbar.update(1)
            
            # 计算完整训练集RMSE
            train_rmse = epoch_train_rmse / len(user_train)
            train_losses.append(np.sqrt(train_rmse))
            
            # 计算测试集上的RMSE
            y_test_pred = model.pred(user_test, item_test)
            test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))
            test_losses.append(test_rmse)
    
    return train_losses, test_losses
```

## 习题6

试通过代码实验来验证双线性模型 `FM` 做回归或分类任务时，其优化目标相对参数是非凸的，也即是，设置不同的参数初始值，使用同样的 `SGD` 学习算法，最后参数会收敛到不同的位置。

**解答**


```python
import numpy as np
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

class FactorizationMachine:
    def __init__(self, n_factors, learning_rate=0.0001, n_iterations=5):
        self.n_factors = n_factors
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations

    def initialize_parameters(self, n_features):
        self.w0 = np.random.normal()
        self.w = np.random.normal(size=n_features)
        self.V = np.random.normal(size=(n_features, self.n_factors))

    def predict(self, X):
        linear_terms = np.dot(X, self.w) + self.w0
        interaction_terms = 0.5 * np.dot(X.dot(self.V), X.dot(self.V).T - np.dot(X ** 2, self.V ** 2).T)
        return linear_terms + interaction_terms

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.initialize_parameters(n_features)

        for _ in range(self.n_iterations):
            for i in range(n_samples):
                x_i = X[i]
                y_i = y[i]
                prediction = self.predict(x_i)
                error = y_i - prediction

                self.w0 += self.learning_rate * error
                self.w += self.learning_rate * error * x_i

                interaction_grad = np.outer(x_i, (x_i.dot(self.V)))
                interaction_grad_squared = np.outer(np.square(x_i), np.square(self.V).sum(axis=0))
                self.V += self.learning_rate * (error * interaction_grad - interaction_grad_squared)

# 生成回归数据
X_reg, y_reg = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)
scaler = StandardScaler()
X_reg = scaler.fit_transform(X_reg)
y_reg = (y_reg - y_reg.mean()) / y_reg.std()

# 将数据拆分为训练和测试集
X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# 定义具有不同初始参数的FM模型
fm1 = FactorizationMachine(n_factors=5, learning_rate=0.0001, n_iterations=5)
fm2 = FactorizationMachine(n_factors=5, learning_rate=0.0001, n_iterations=5)

# 用相同的训练数据拟合模型
fm1.fit(X_train, y_train)
fm2.fit(X_train, y_train)

# 预测测试数据
y_pred1 = fm1.predict(X_test)
y_pred2 = fm2.predict(X_test)

# 计算均方误差，忽略NaN值
mse1 = np.nanmean((y_test - y_pred1) ** 2)
mse2 = np.nanmean((y_test - y_pred2) ** 2)

print("\nMean Squared Error of FM Model 1:", mse1)
print("Mean Squared Error of FM Model 2:", mse2)

```

    
    Mean Squared Error of FM Model 1: 9.66424222458966
    Mean Squared Error of FM Model 2: 6.3303425488369305
    

优化目标相对于参数是非凸的，是因为在FM（Factorization Machines）模型中，损失函数通常是一个非凸函数。FM模型的目标是最小化损失函数，而损失函数通常由两部分组成：一个是模型预测值与实际值之间的差异，另一个是正则化项（如果有的话）。

在FM模型中，由于存在交互项的双线性部分，导致整个模型的目标函数通常是一个非凸函数。具体来说，双线性部分的参数是相互关联的，当进行参数优化时，优化过程可能会陷入局部最优解，因为目标函数存在多个局部极小值点，使得最终的优化结果取决于初始参数值以及优化算法的选择。

如果优化目标是凸的，无论初始参数如何，都应该收敛到同一个全局最优解。实验表明不同初始化导致不同的最终参数和性能，证明了FM模型优化目标的非凸性。


这种非凸性质使得FM模型的参数优化变得复杂，并且可能导致不同的优化结果，即使使用相同的优化算法和超参数设置。因此，为了得到较好的模型性能，通常需要多次运行模型，并选择其中表现最好的结果。
