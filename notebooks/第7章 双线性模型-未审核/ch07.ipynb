{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7章 双线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下关于双线性模型的说法，不正确的是：\n",
    "\n",
    "&emsp; A. 双线性模型考虑了特征之间的关联，比线性模型建模能力更强。  \n",
    "&emsp; B. 在因子分解机中，因为引入了特征的乘积，只有特征 $x_i$ 与 $x_j$ 都不为零时才能更新参数 $w_{ij}$ 。   \n",
    "&emsp; C. 可以通过重新设置参数，把因子分解机中的常数项和一次项都合并到二次项里，得到更一般的表达式。  \n",
    "&emsp; D. 在矩阵分解中，最优的特征数量$d$是超参数，不能通过公式推导出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp; **答案：C**  \n",
    "  \n",
    "&emsp;&emsp; A. 正确。双线性模型通过引入特征之间的交互项，能够捕捉特征间的关联性，能对更加复杂的场景进行建模，也可以通过设置参数退化到线性模型，因此比单纯的线性模型具有更强的建模能力。   \n",
    "&emsp;&emsp; B. 正确。在因子分解机中，特征交互项 $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle x_i x_j$ 只有在 $x_i$ 和 $x_j$ 都不为零时才会产生影响，此时才能通过梯度更新相应的参数 $w_{ij}$ 。  \n",
    "&emsp;&emsp; C. 错误。因子分解机的表达式为 $y = w_0 + \\sum_{i=1}^n w_i x_i + \\sum_{i=1}^n\\sum_{j=i+1}^n \\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle x_i x_j$ ，其中包含常数项、一次项和二次项。无法通过简单地重新设置参数将常数项和一次项都合并到二次项中，因为当某些特征为零时，对应的二次项也会为零，而一次项和常数项仍然存在。  \n",
    "&emsp;&emsp; D. 正确。在矩阵分解中，隐因子的维度$d$是需要通过交叉验证等方法确定的超参数，无法通过理论公式直接推导出最优值。或可以使用启发式算法来选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下哪一个模型不是关于双线性模型：  \n",
    "&emsp; A. $f(\\theta_1, \\theta_2) = \\theta_1 \\theta_2$  \n",
    "&emsp; B. $f(\\theta_1, \\theta_2) = \\langle\\theta_1, \\theta_2\\rangle$  \n",
    "&emsp; C. $f(\\theta_1, \\theta_2) = 0$  \n",
    "&emsp; D. $f(\\theta_1, \\theta_2) = e^{\\theta_1} e^{\\theta_2}$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**答案：D**    \n",
    "  \n",
    "&emsp;&emsp; A. 正确。是乘积（相互作用）。  \n",
    "&emsp;&emsp; B. 正确。是内积（相似性）。  \n",
    "&emsp;&emsp; C. 正确。$f(\\theta_1, \\theta_2) = 0$ 是常数函数，可以视为特殊情况的双线性函数（系数都为0）。它对任意变量都是线性的。  \n",
    "&emsp;&emsp; D. 错误。$f(\\theta_1, \\theta_2) = e^{\\theta_1} e^{\\theta_2}$ 不是双线性的。  \n",
    "&emsp;&emsp; 验证选项D：  \n",
    "&emsp;&emsp; 对于双线性函数，应满足 $f(\\theta_1+t, \\theta_2) = f(\\theta_1, \\theta_2) + f(t, \\theta_2)$  \n",
    "&emsp;&emsp; 但 $f(\\theta_1+t, \\theta_2) = e^{\\theta_1+t} e^{\\theta_2} = e^{\\theta_1} e^{t} e^{\\theta_2}$  \n",
    "&emsp;&emsp; 而 $f(\\theta_1, \\theta_2) + f(t, \\theta_2) = e^{\\theta_1} e^{\\theta_2} + e^{t} e^{\\theta_2} = e^{\\theta_2}(e^{\\theta_1} + e^{t})$  \n",
    "&emsp;&emsp; 显然 $e^{\\theta_1} e^{t} e^{\\theta_2} \\neq e^{\\theta_2}(e^{\\theta_1} + e^{t})$ ，因此不满足双线性性质。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于多域独热编码，思考其相比于如下编码方式的优势：针对每一个域，依次把其中的离散取值以自然数（以 0 开始）作为编码，在编码后每个域就对应一个自然数。例如图 7-3 中产地上海对应为 1，深圳对应为 3，生产月份 2 月对应为 1，12 月对应为 11，食品种类乳制品对应为 0，图中的整个编码向量为 (1, 2, …, 0)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;多域独热编码相比于自然数编码有以下优势：  \n",
    "  \n",
    "- 避免数值影响。数值大小在计算中可能会对模型的影响不一样，独热编码可以统一为二进制。\n",
    "- 避免不必要的相关性。自然数编码数字之间模型可能会认为特征会存在相关性，不像二进制直接划分，1-9的自然数模型可能会认为不同的数字也会产生相关性。\n",
    "- 处理缺失值。如果某个域缺失了，自然数编码该分配什么编码呢？独热编码会分配一个全零向量。\n",
    "- 更好地找到特征的关系。独热编码进行交叉乘积可以明显地得到特征之间的关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试修改 MF 的 `pred(self, user_id, item_id)` 函数，在模型预测中加入全局打分偏置、用户打分偏置和物品打分偏置，类似 `FM`模型中的常数项部分，观察模型拟合性能指标的变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp; 加入偏置可以获得更好的模型拟合，提高模型的泛化能力  \n",
    "&emsp;&emsp; 实验证明，加入偏置项使用原超参数大小直接梯度爆炸了，调整超参数后依然过拟合  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小： 100000\n",
      "用户数：943，电影数：1682\n",
      "[215  47  42  19 139 170 320  47  18 156]\n",
      "[371 109  70 172  70  21 308 158 240  68]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # 进度条工具\n",
    "\n",
    "data = np.loadtxt('movielens_100k.csv', delimiter=',', dtype=int)\n",
    "print('数据集大小：', len(data))\n",
    "# 用户和电影都是从1开始编号的，我们将其转化为从0开始\n",
    "data[:, :2] = data[:, :2] - 1\n",
    "\n",
    "# 计算用户和电影数量\n",
    "users = set()\n",
    "items = set()\n",
    "for i, j, k in data:\n",
    "    users.add(i)\n",
    "    items.add(j)\n",
    "user_num = len(users)\n",
    "item_num = len(items)\n",
    "print(f'用户数：{user_num}，电影数：{item_num}')\n",
    "\n",
    "# 设置随机种子，划分训练集与测试集\n",
    "np.random.seed(0)\n",
    "\n",
    "ratio = 0.8\n",
    "split = int(len(data) * ratio)\n",
    "np.random.shuffle(data)\n",
    "train = data[:split]\n",
    "test = data[split:]\n",
    "\n",
    "# 统计训练集中每个用户和电影出现的数量，作为正则化的权重\n",
    "user_cnt = np.bincount(train[:, 0], minlength=user_num)\n",
    "item_cnt = np.bincount(train[:, 1], minlength=item_num)\n",
    "print(user_cnt[:10])\n",
    "print(item_cnt[:10])\n",
    "\n",
    "# ----------------------------------------\n",
    "# 添加全局打分偏置、用户打分偏置和电影打分偏置\n",
    "# 初始化全局打分偏置、用户打分偏置和电影打分偏置\n",
    "global_bias = np.mean(train[:, 2])\n",
    "user_biases = np.zeros(user_num)\n",
    "\n",
    "\n",
    "item_biases = np.zeros(item_num)\n",
    "\n",
    "# 计算每个用户和电影的平均打分\n",
    "user_means = np.zeros(user_num)\n",
    "item_means = np.zeros(item_num)\n",
    "user_cnt = np.bincount(train[:, 0], minlength=user_num)\n",
    "item_cnt = np.bincount(train[:, 1], minlength=item_num)\n",
    "for i, j, k in train:\n",
    "    user_means[i] += k\n",
    "    item_means[j] += k\n",
    "user_means = np.divide(user_means, user_cnt, out=np.zeros_like(user_means), where=user_cnt!=0)\n",
    "item_means = np.divide(item_means, item_cnt, out=np.zeros_like(item_means), where=item_cnt!=0)\n",
    "\n",
    "# 计算用户和电影的打分偏置\n",
    "user_biases = user_means - global_bias\n",
    "item_biases = item_means - global_bias\n",
    "# ----------------------------------------\n",
    "\n",
    "# 用户和电影的编号要作为下标，必须保存为整数\n",
    "user_train, user_test = train[:, 0], test[:, 0]\n",
    "item_train, item_test = train[:, 1], test[:, 1]\n",
    "y_train, y_test = train[:, 2], test[:, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF:\n",
    "\n",
    "    def __init__(self, N, M, d):\n",
    "        # N是用户数量，M是电影数量，d是特征维度\n",
    "        # 定义模型参数\n",
    "        self.user_params = np.ones((N, d))\n",
    "        self.item_params = np.ones((M, d))\n",
    "        self.global_bias = 0\n",
    "        self.user_biases = np.zeros(N)\n",
    "        self.item_biases = np.zeros(M)\n",
    "\n",
    "    def pred(self, user_id, item_id):\n",
    "        # 预测用户user_id对电影item_id的打分\n",
    "        # 获得用户偏好和电影特征\n",
    "        user_param = self.user_params[user_id]\n",
    "        item_param = self.item_params[item_id]\n",
    "        # 计算用户和电影的交互作用\n",
    "        interaction = np.sum(user_param * item_param, axis=1)\n",
    "        # 加入全局打分偏置、用户打分偏置和电影打分偏置\n",
    "        global_bias = self.global_bias\n",
    "        user_bias = self.user_biases[user_id]\n",
    "        item_bias = self.item_biases[item_id]\n",
    "        rating_pred = global_bias + user_bias + item_bias + interaction\n",
    "        \n",
    "        return rating_pred\n",
    "\n",
    "    def update(self, user_grad, item_grad, lr):\n",
    "        # 根据参数的梯度更新参数\n",
    "        self.user_params -= lr * user_grad\n",
    "        self.item_params -= lr * item_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, learning_rate, lbd, max_training_step, batch_size):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    batch_num = int(np.ceil(len(user_train) / batch_size))\n",
    "    with tqdm(range(max_training_step * batch_num)) as pbar:\n",
    "        for epoch in range(max_training_step):\n",
    "            # 随机梯度下降\n",
    "            train_rmse = 0\n",
    "            for i in range(batch_num):\n",
    "                # 获取当前批量\n",
    "                st = i * batch_size\n",
    "                ed = min(len(user_train), st + batch_size)\n",
    "                user_batch = user_train[st: ed]\n",
    "                item_batch = item_train[st: ed]\n",
    "                y_batch = y_train[st: ed]\n",
    "                # 计算模型预测\n",
    "                y_pred = model.pred(user_batch, item_batch)\n",
    "                # 计算梯度\n",
    "                P = model.user_params\n",
    "                Q = model.item_params\n",
    "                errs = y_batch - y_pred\n",
    "                P_grad = np.zeros_like(P)\n",
    "                Q_grad = np.zeros_like(Q)\n",
    "                # 加入偏置的梯度\n",
    "                global_bias_grad = 0\n",
    "                user_bias_grad = np.zeros_like(model.user_biases)\n",
    "                item_bias_grad = np.zeros_like(model.item_biases) \n",
    "\n",
    "                for user, item, err in zip(user_batch, item_batch, errs):\n",
    "                    P_grad[user] = P_grad[user] - err * Q[item] + lbd * P[user]\n",
    "                    Q_grad[item] = Q_grad[item] - err * P[user] + lbd * Q[item]\n",
    "                    interaction = np.sum(P[user] * Q[item])\n",
    "                    global_bias_grad -= err\n",
    "                    user_bias_grad[user] -= err\n",
    "                    item_bias_grad[item] -= err\n",
    "                # 更新全局打分偏置\n",
    "                model.global_bias += learning_rate * global_bias_grad / len(user_batch)\n",
    "                # 更新用户打分偏置\n",
    "                model.user_biases += learning_rate * user_bias_grad / len(user_batch)\n",
    "                # 更新电影打分偏置\n",
    "                model.item_biases += learning_rate * item_bias_grad / len(user_batch)\n",
    "                \n",
    "                model.update(P_grad / len(user_batch), Q_grad / len(user_batch), learning_rate)\n",
    "                \n",
    "                train_rmse += np.mean(errs ** 2)\n",
    "                # 更新进度条\n",
    "                pbar.set_postfix({\n",
    "                    'Epoch': epoch,\n",
    "                    'Train RMSE': f'{np.sqrt(train_rmse / (i + 1)):.4f}',\n",
    "                    'Test RMSE': f'{test_losses[-1]:.4f}' if test_losses else None\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "            # 计算测试集上的RMSE\n",
    "            train_rmse = np.sqrt(train_rmse / len(user_train))\n",
    "            train_losses.append(train_rmse)\n",
    "            y_test_pred = model.pred(user_test, item_test)\n",
    "            test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))\n",
    "            test_losses.append(test_rmse)\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:41<00:00, 301.26it/s, Epoch=9, Train RMSE=1.8535, Test RMSE=154.5553] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 超参数\n",
    "feature_num = 128 # 特征数\n",
    "learning_rate = 0.01 # 学习率\n",
    "lbd = 1e-1 # 正则化强度\n",
    "max_training_step = 10\n",
    "batch_size = 64 # 批量大小\n",
    "\n",
    "# 建立模型\n",
    "model = MF(user_num, item_num, feature_num)\n",
    "# 训练部分\n",
    "train_losses, test_losses = train(model, learning_rate, lbd,\n",
    "    max_training_step, batch_size)\n",
    "\n",
    "plt.figure()\n",
    "x = np.arange(max_training_step) + 1\n",
    "plt.plot(x, train_losses, color='blue', label='train loss')\n",
    "plt.plot(x, test_losses, color='red', ls='--', label='test loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.31120225 4.556555   2.76502584 4.78647637 5.78246472 3.35982054\n",
      " 4.1325364  2.84627579 2.25076913 3.12091915]\n",
      "[2 4 4 4 5 2 3 1 4 4]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.pred(user_test, item_test)\n",
    "print(y_test_pred[:10]) # 把张量转换为numpy数组\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试基于本章的`MF`代码，调试不同的超参数，包括 $k$ 和 $\\lambda$ ，关注训练集和测试集的性能指标的改变，根据训练和测试的性能曲线，判定哪些超参数导致过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小： 100000\n",
      "用户数：943，电影数：1682\n",
      "[215  47  42  19 139 170 320  47  18 156]\n",
      "[371 109  70 172  70  21 308 158 240  68]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # 进度条工具\n",
    "\n",
    "data = np.loadtxt('movielens_100k.csv', delimiter=',', dtype=int)\n",
    "print('数据集大小：', len(data))\n",
    "# 用户和电影都是从1开始编号的，我们将其转化为从0开始\n",
    "data[:, :2] = data[:, :2] - 1\n",
    "\n",
    "# 计算用户和电影数量\n",
    "users = set()\n",
    "items = set()\n",
    "for i, j, k in data:\n",
    "    users.add(i)\n",
    "    items.add(j)\n",
    "user_num = len(users)\n",
    "item_num = len(items)\n",
    "print(f'用户数：{user_num}，电影数：{item_num}')\n",
    "\n",
    "# 设置随机种子，划分训练集与测试集\n",
    "np.random.seed(0)\n",
    "\n",
    "ratio = 0.8\n",
    "split = int(len(data) * ratio)\n",
    "np.random.shuffle(data)\n",
    "train = data[:split]\n",
    "test = data[split:]\n",
    "\n",
    "# 统计训练集中每个用户和电影出现的数量，作为正则化的权重\n",
    "user_cnt = np.bincount(train[:, 0], minlength=user_num)\n",
    "item_cnt = np.bincount(train[:, 1], minlength=item_num)\n",
    "print(user_cnt[:10])\n",
    "print(item_cnt[:10])\n",
    "\n",
    "# 用户和电影的编号要作为下标，必须保存为整数\n",
    "user_train, user_test = train[:, 0], test[:, 0]\n",
    "item_train, item_test = train[:, 1], test[:, 1]\n",
    "y_train, y_test = train[:, 2], test[:, 2]\n",
    "\n",
    "class MF:\n",
    "    \n",
    "    def __init__(self, N, M, d):\n",
    "        # N是用户数量，M是电影数量，d是特征维度\n",
    "        # 定义模型参数\n",
    "        self.user_params = np.ones((N, d))\n",
    "        self.item_params = np.ones((M, d))\n",
    "        \n",
    "    def pred(self, user_id, item_id):\n",
    "        # 预测用户user_id对电影item_id的打分\n",
    "        # 获得用户偏好和电影特征\n",
    "        user_param = self.user_params[user_id]\n",
    "        item_param = self.item_params[item_id]\n",
    "        # 返回预测的评分\n",
    "        if isinstance(user_id, np.ndarray) and len(user_id) > 1:\n",
    "            # 批量预测\n",
    "            rating_pred = np.sum(user_param * item_param, axis=1)\n",
    "        else:\n",
    "            # 单个预测\n",
    "            rating_pred = np.sum(user_param * item_param)\n",
    "            \n",
    "        return rating_pred\n",
    "\n",
    "    def update(self, user_grad, item_grad, lr):\n",
    "        # 根据参数的梯度更新参数\n",
    "        self.user_params -= lr * user_grad\n",
    "        self.item_params -= lr * item_grad\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, learning_rate, lbd, max_training_step, batch_size):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    batch_num = int(np.ceil(len(user_train) / batch_size))\n",
    "    with tqdm(range(max_training_step * batch_num)) as pbar:\n",
    "        for epoch in range(max_training_step):\n",
    "            # 随机梯度下降\n",
    "            train_rmse = 0\n",
    "            for i in range(batch_num):\n",
    "                # 获取当前批量\n",
    "                st = i * batch_size\n",
    "                ed = min(len(user_train), st + batch_size)\n",
    "                user_batch = user_train[st: ed]\n",
    "                item_batch = item_train[st: ed]\n",
    "                y_batch = y_train[st: ed]\n",
    "                # 计算模型预测\n",
    "                y_pred = model.pred(user_batch, item_batch)\n",
    "                # 计算梯度\n",
    "                P = model.user_params\n",
    "                Q = model.item_params\n",
    "                errs = y_batch - y_pred\n",
    "                P_grad = np.zeros_like(P)\n",
    "                Q_grad = np.zeros_like(Q)\n",
    "                for user, item, err in zip(user_batch, item_batch, errs):\n",
    "                    P_grad[user] = P_grad[user] - err * Q[item] + lbd * P[user]\n",
    "                    Q_grad[item] = Q_grad[item] - err * P[user] + lbd * Q[item]\n",
    "                model.update(P_grad / len(user_batch), Q_grad / len(user_batch), learning_rate)\n",
    "                \n",
    "                train_rmse += np.mean(errs ** 2)\n",
    "                # 更新进度条\n",
    "                pbar.set_postfix({\n",
    "                    'Epoch': epoch,\n",
    "                    'Train RMSE': f'{np.sqrt(train_rmse / (i + 1)):.4f}',\n",
    "                    'Test RMSE': f'{test_losses[-1]:.4f}' if test_losses else None\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "            # 计算 RMSE 损失\n",
    "            train_rmse = np.sqrt(train_rmse / len(user_train))\n",
    "            train_losses.append(train_rmse)\n",
    "            y_test_pred = model.pred(user_test, item_test)\n",
    "            test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))\n",
    "            test_losses.append(test_rmse)\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, learning_rate, lbd, max_training_step, batch_size):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    batch_num = int(np.ceil(len(user_train) / batch_size))\n",
    "    with tqdm(range(max_training_step * batch_num)) as pbar:\n",
    "        for epoch in range(max_training_step):\n",
    "            # 随机打乱训练数据的顺序\n",
    "            indices = np.random.permutation(len(user_train))\n",
    "            shuffled_user_train = user_train[indices]\n",
    "            shuffled_item_train = item_train[indices]\n",
    "            shuffled_y_train = y_train[indices]\n",
    "            \n",
    "            # 随机梯度下降\n",
    "            epoch_train_rmse = 0\n",
    "            for i in range(batch_num):\n",
    "                # 获取当前批量\n",
    "                st = i * batch_size\n",
    "                ed = min(len(shuffled_user_train), st + batch_size)\n",
    "                # 确保当前批次有足够的数据\n",
    "                if ed <= st:\n",
    "                    continue\n",
    "                    \n",
    "                user_batch = shuffled_user_train[st:ed]\n",
    "                item_batch = shuffled_item_train[st:ed]\n",
    "                y_batch = shuffled_y_train[st:ed]\n",
    "                \n",
    "                # 计算模型预测\n",
    "                y_pred = model.pred(user_batch, item_batch)\n",
    "                \n",
    "                # 确保形状匹配\n",
    "                if len(y_pred) != len(y_batch):\n",
    "                    raise ValueError(f\"Prediction shape {len(y_pred)} doesn't match target shape {len(y_batch)}\")\n",
    "                    \n",
    "                # 计算梯度\n",
    "                P = model.user_params\n",
    "                Q = model.item_params\n",
    "                errs = y_batch - y_pred\n",
    "                P_grad = np.zeros_like(P)\n",
    "                Q_grad = np.zeros_like(Q)\n",
    "                \n",
    "                for user, item, err in zip(user_batch, item_batch, errs):\n",
    "                    P_grad[user] = P_grad[user] - err * Q[item] + lbd * P[user] \n",
    "                    Q_grad[item] = Q_grad[item] - err * P[user] + lbd * Q[item]\n",
    "                    \n",
    "                model.update(P_grad / len(user_batch), Q_grad / len(user_batch), learning_rate)\n",
    "                \n",
    "                batch_rmse = np.sqrt(np.mean(errs ** 2))\n",
    "                epoch_train_rmse += batch_rmse * len(user_batch)\n",
    "                \n",
    "                # 更新进度条\n",
    "                pbar.set_postfix({\n",
    "                    'Epoch': epoch,\n",
    "                    'Train RMSE': f'{batch_rmse:.4f}',\n",
    "                    'Test RMSE': f'{test_losses[-1]:.4f}' if test_losses else 'N/A'\n",
    "                })\n",
    "                pbar.update(1)\n",
    "            \n",
    "            # 计算完整训练集RMSE\n",
    "            train_rmse = epoch_train_rmse / len(user_train)\n",
    "            train_losses.append(np.sqrt(train_rmse))\n",
    "            \n",
    "            # 计算测试集上的RMSE\n",
    "            y_test_pred = model.pred(user_test, item_test)\n",
    "            test_rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))\n",
    "            test_losses.append(test_rmse)\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试通过代码实验来验证双线性模型 `FM` 做回归或分类任务时，其优化目标相对参数是非凸的，也即是，设置不同的参数初始值，使用同样的 `SGD` 学习算法，最后参数会收敛到不同的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Squared Error of FM Model 1: 9.66424222458966\n",
      "Mean Squared Error of FM Model 2: 6.3303425488369305\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class FactorizationMachine:\n",
    "    def __init__(self, n_factors, learning_rate=0.0001, n_iterations=5):\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize_parameters(self, n_features):\n",
    "        self.w0 = np.random.normal()\n",
    "        self.w = np.random.normal(size=n_features)\n",
    "        self.V = np.random.normal(size=(n_features, self.n_factors))\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_terms = np.dot(X, self.w) + self.w0\n",
    "        interaction_terms = 0.5 * np.dot(X.dot(self.V), X.dot(self.V).T - np.dot(X ** 2, self.V ** 2).T)\n",
    "        return linear_terms + interaction_terms\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.initialize_parameters(n_features)\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            for i in range(n_samples):\n",
    "                x_i = X[i]\n",
    "                y_i = y[i]\n",
    "                prediction = self.predict(x_i)\n",
    "                error = y_i - prediction\n",
    "\n",
    "                self.w0 += self.learning_rate * error\n",
    "                self.w += self.learning_rate * error * x_i\n",
    "\n",
    "                interaction_grad = np.outer(x_i, (x_i.dot(self.V)))\n",
    "                interaction_grad_squared = np.outer(np.square(x_i), np.square(self.V).sum(axis=0))\n",
    "                self.V += self.learning_rate * (error * interaction_grad - interaction_grad_squared)\n",
    "\n",
    "# 生成回归数据\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_reg = scaler.fit_transform(X_reg)\n",
    "y_reg = (y_reg - y_reg.mean()) / y_reg.std()\n",
    "\n",
    "# 将数据拆分为训练和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义具有不同初始参数的FM模型\n",
    "fm1 = FactorizationMachine(n_factors=5, learning_rate=0.0001, n_iterations=5)\n",
    "fm2 = FactorizationMachine(n_factors=5, learning_rate=0.0001, n_iterations=5)\n",
    "\n",
    "# 用相同的训练数据拟合模型\n",
    "fm1.fit(X_train, y_train)\n",
    "fm2.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试数据\n",
    "y_pred1 = fm1.predict(X_test)\n",
    "y_pred2 = fm2.predict(X_test)\n",
    "\n",
    "# 计算均方误差，忽略NaN值\n",
    "mse1 = np.nanmean((y_test - y_pred1) ** 2)\n",
    "mse2 = np.nanmean((y_test - y_pred2) ** 2)\n",
    "\n",
    "print(\"\\nMean Squared Error of FM Model 1:\", mse1)\n",
    "print(\"Mean Squared Error of FM Model 2:\", mse2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化目标相对于参数是非凸的，是因为在FM（Factorization Machines）模型中，损失函数通常是一个非凸函数。FM模型的目标是最小化损失函数，而损失函数通常由两部分组成：一个是模型预测值与实际值之间的差异，另一个是正则化项（如果有的话）。\n",
    "\n",
    "在FM模型中，由于存在交互项的双线性部分，导致整个模型的目标函数通常是一个非凸函数。具体来说，双线性部分的参数是相互关联的，当进行参数优化时，优化过程可能会陷入局部最优解，因为目标函数存在多个局部极小值点，使得最终的优化结果取决于初始参数值以及优化算法的选择。\n",
    "\n",
    "如果优化目标是凸的，无论初始参数如何，都应该收敛到同一个全局最优解。实验表明不同初始化导致不同的最终参数和性能，证明了FM模型优化目标的非凸性。\n",
    "\n",
    "\n",
    "这种非凸性质使得FM模型的参数优化变得复杂，并且可能导致不同的优化结果，即使使用相同的优化算法和超参数设置。因此，为了得到较好的模型性能，通常需要多次运行模型，并选择其中表现最好的结果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
