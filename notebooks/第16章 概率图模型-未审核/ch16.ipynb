{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第16章 概率图模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题1\n",
    "下以下关于概率图模型的说法错误的是（ ）。  \n",
    "&emsp; A. 图分有向图和无向图两种，分别表示变量间的单向和双向依赖关系。   \n",
    "&emsp; B. 概率图的有效建立往往需要人的先验知识。  \n",
    "&emsp; C. 泛贝叶斯网络导出的MAP和MLE解是等价的。   \n",
    "&emsp; D. 不同马尔可夫网络中势能越高的状态出现的概率越低。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**答案：C、D**\n",
    "\n",
    "&emsp;&emsp;选项A：正确。有向图（如贝叶斯网络）表示单向依赖，无向图（如马尔可夫随机场）表示双向依赖。  \n",
    "&emsp;&emsp;选项B：正确。概率图的构建需要领域知识确定变量间的依赖结构。  \n",
    "&emsp;&emsp;选项C：错误。MAP（最大后验估计）与MLE（最大似然估计）仅在先验为均匀分布时等价，而“泛贝叶斯网络”未限定先验条件，故两者通常不等价。  \n",
    "&emsp;&emsp;选项D：错误。马尔可夫网络的联合概率与势函数的乘积成正比，势能（势函数值）越高，状态出现的概率越高。选项D的表述与这一关系矛盾。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题2\n",
    "\n",
    "以下关于条件独立的说法，不正确的是？   \n",
    "&emsp; A. 条件独立的定义是：考虑3个变量$a,b,c$假设给定$b$和$c$的情况下，$a$的条件分布不依赖于$b$的值，则在给定$c$的情况下$a$条件独立于$b$。   \n",
    "&emsp; B. 图模型中的尾对尾结构中，当父节点未被观测到时，其子节点之间将不会条件独立   \n",
    "&emsp; C. 图模型中的头对尾结构中，当中间节点未被观测到时，其两头的节点之间将不会条件独立   \n",
    "&emsp; D. 图模型中的头对头结构中，当子节点未被观测到时，其父节点之间将不会条件独立  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**答案：D**\n",
    "   \n",
    "&emsp;&emsp;选项A 正确。条件独立的定义是：若给定条件 cc 时，aa 的分布不依赖于 bb，则称 aa 和 bb 在给定 cc 时条件独立。选项A的描述符合这一定义。  \n",
    "&emsp;&emsp;选项B 正确。尾对尾结构（如 a \\leftarrow c \\rightarrow ba←c→b）中，若父节点 cc 未被观测，aa 和 bb 因共享父节点而依赖，故不会条件独立。  \n",
    "&emsp;&emsp;选项C 正确。头对尾结构（如 a \\rightarrow c \\rightarrow ba→c→b）中，若中间节点 cc 未被观测，路径未被阻塞，aa 和 bb 保持依赖关系，故不会条件独立。    \n",
    "&emsp;&emsp;选项D 错误。头对头结构（如 a \\rightarrow c \\leftarrow ba→c←b）中，当子节点 cc 未被观测时，父节点 aa 和 bb 是独立的（路径被阻塞）；仅当 cc 或其后代被观测时，aa 和 bb 才可能相关。因此，选项D的表述与实际情况相反。  \n",
    " \n",
    "&emsp;&emsp;在概率图模型中，未观测的节点包含了其他节点的信息，会使得节点变量之间产生关联，被观测后，就确定了这些信息，使得其他节点变量条件独立（不会因为另一个节点变化而产生未知信息相互影响）     \n",
    "![3个变量的依赖关系](https://hml.boyuai.com/static/cond_ind.drawio.68e92fbc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在线性模型中，假设参数$w$的先验分布是偏移参数为$\\mu=0$、尺度参数为$b$的拉普拉斯分布，其概率密度函数为\n",
    "$$p(w|\\mu=0,b)=\\frac{1}{2b}\\exp(-\\frac{|w|}{b})$$\n",
    "仿照 16.2 节中的推导（此处原书为16.1应更改为16.2，利用MAP求解此时的优化目标。这个目标相当于为线性模型添加了什么正则化约束？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 答案：\n",
    "\n",
    "$y$ 和 $w$ 的概率分布：\n",
    "$$\n",
    "p(y, w|X) = p(y|w, X) p(w) = p(w)\\prod_{i=1}^{N}p(y_i|w, x_i)\n",
    "$$\n",
    "\n",
    "根据贝叶斯公式，模型参数 $w$ 的后验分布表示为：\n",
    "$$\n",
    "p(w|X, y)=\\frac{p(y, w|X)}{p(y|X)} \\propto p(w) \\prod_{i=1}^{N}p(y_i|w, x_i)\n",
    "$$\n",
    "\n",
    "设参数 $w$ 的先验分布是偏移参数为 $\\mu=0$，尺度参数为 $b$ 的拉普拉斯分布，概率分布：\n",
    "$$\n",
    "p(w|\\mu=0, b)=\\frac{1}{2b}\\exp(-\\frac{|w|}{b})\n",
    "$$\n",
    "即 $w$ 服从拉普拉斯分布，表示为 $w \\sim \\text{Laplace}(0, b)$。\n",
    "\n",
    "假设 $y_i$ 和 $x_i$ 和 $w$ 之间的关系服从高斯分布，满足：\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_i &\\sim \\mathcal{N}(x_i^T w, \\sigma^2) \\\\\n",
    "p(y_i | x_i, w, \\sigma^2) &\\sim \\mathcal{N}(y_i | x_i^T w, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - w^T x_i)^2}{2\\sigma^2})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "那么后验分布可以表示为：\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(w|X, y) & \\propto p(w) \\prod_{i=1}^{N}p(y_i|w, x_i) \\\\\n",
    "& \\propto p(w | \\mu=0, b) \\prod_{i=1}^{N} \\mathcal{N}(y_i | x_i^T w, \\sigma^2)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "最大后验估计 MAP：\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\arg \\max_{w} p(w|X, y) \n",
    "& = \\arg \\max_{w} \\left( p(w | \\mu=0, b) \\prod_{i=1}^{N} \\mathcal{N}(y_i | x_i^T w, \\sigma^2)\\right) \\\\\n",
    "& = \\arg \\max_{w} \\left(\\frac{1}{2b}\\exp(-\\frac{|w|}{b}) \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - w^T x_i)^2}{2\\sigma^2})\\right) \\\\\n",
    "& \\text{取对数，连乘变连加} \\\\\n",
    "& = \\arg\\max_{w}\\log \\left(\\frac{1}{2b}\\exp(-\\frac{|w|}{b}) \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - w^T x_i)^2}{2\\sigma^2})\\right) \\\\\n",
    "& = \\arg\\max_{w} \\left(\\log(\\frac{1}{2b}\\exp(-\\frac{|w|}{b})) + \\sum_{i=1}^{N}\\log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(y_i - w^T x_i)^2}{2\\sigma^2}))\\right) \\\\\n",
    "& \\log(\\frac{1}{2b}) \\text{和} \\log(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) \\text{是常数，对} w \\text{没影响，可以忽略} \\\\\n",
    "& = \\arg\\max_{w}\\left(-\\frac{|w|}{b} - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}(y_i - w^T x_i)^2 \\right) \\\\\n",
    "& = \\arg \\min_{w}\\left(\\frac{|w|}{b} + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}(y_i - w^T x_i)^2 \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "因此，最终要解决的优化问题是：\n",
    "$$\n",
    "\\min_{w}\\left(\\frac{|w|}{b} + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}(y_i - w^T x_i)^2 \\right)\n",
    "$$\n",
    "\n",
    "这个优化目标函数，相当于给线性模型添加了 L1 和 L2 正则化约束：\n",
    "- $\\frac{|w|}{b}$ 是关于 $w$ 的 L1 正则化\n",
    "- $\\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - w^T x_i)^2$ 是平方误差损失项，为 L2 正则化项，可以看作是 $w$ 的 L2 范数的平方乘以系数 $\\frac{1}{2\\sigma^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题4\n",
    "把一句话中的每个词看作一个单元，为了构成完整的具有语义的句子，这些单元之间必然存在关联。这种关联用哪种概率模型描述更合适？简要画出相应的概率图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把一句话中的每个词看作一个单元，为了构成完整的具有语义的句子，这些单元之间必然存在关联，更合适描述这种关联的模型是有向图模型中的马尔可夫链（如一阶马尔可夫模型或n-gram模型）。每个词作为节点，箭头表示依赖关系，即当前词的概率依赖于前一个词的值。这种模型能捕捉序列中词的单向依赖，适合生成句子时的顺序性。\n",
    "\n",
    "马尔可夫模型的概率图如下：\n",
    "\n",
    "以隐马尔可夫模型为例，假设句子由一系列词 $$w1\\to w2\\to w3\\to\\ldots\\to wn$$ 组成，每个词 $w1$ 依赖于其前一个词 wi-1$。概率图可以表示为一个链式结构，其中每个节点代表一个词，边表示词之间的依赖关系。\n",
    "\n",
    "$\\begin{aligned} & 具体例子： \\\\ & 假设句子是“我爱学习”,对应的概率图如下: \\\\ & 我\\to 爱\\to 学习 \\\\ & 每个词的概率可以表示为: \\\\ & \\bullet P(\\text{我):句子开头词“我”的概率。}| \\\\ & \\bullet P(\\text{爱}|\\text{我})\\text{:在“我”出现的情况下,“爱”出现的概率。} \\\\ & \\bullet P(\\text{学习|爱):在“爱”出现的情况下,“学习”出现的概率。} \\end{aligned}$\n",
    "\n",
    "通过这种链式结构，可以捕捉句子中词与词之间的顺序依赖关系，从而描述构成完整语义句子的词单元之间的关联。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题5\n",
    "如果要扩展图像去噪中像素之间的关联，认为任意一个像素和周围的8个像素有关，对应的马尔可夫网络和能量函数要怎样变化？修改相应的代码，观察去噪结果是否有变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "带噪图像与原图不一致的像素比例：9.9386%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 读取原图\n",
    "orig_img = np.array(mpimg.imread('.\\\\origimg.jpg'), dtype=int)\n",
    "orig_img[orig_img < 128] = -1 # 黑色设置为-1\n",
    "orig_img[orig_img >= 128] = 1 # 白色设置为1\n",
    "\n",
    "# 读取带噪图像\n",
    "noisy_img = np.array(mpimg.imread('.\\\\noisyimg.jpg'), dtype=int)\n",
    "noisy_img[noisy_img < 128] = -1\n",
    "noisy_img[noisy_img >= 128] = 1\n",
    "\n",
    "def compute_noise_rate(noisy, orig):\n",
    "    err = np.sum(noisy != orig)\n",
    "    return err / orig.size\n",
    "\n",
    "init_noise_rate = compute_noise_rate(noisy_img, orig_img)\n",
    "print (f'带噪图像与原图不一致的像素比例：{init_noise_rate * 100:.4f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邻居方向组合：[(1, 0), (-1, 0), (0, 1), (0, -1)]\n",
      "迭代轮数：0，噪声率：0.5464%\n",
      "迭代轮数：1，噪声率：0.4675%\n",
      "迭代轮数：2，噪声率：0.4443%\n",
      "迭代轮数：3，噪声率：0.4357%\n",
      "迭代轮数：4，噪声率：0.4332%\n",
      "\n",
      "邻居方向组合：[(0, 1), (1, 0), (-1, 0)]\n",
      "迭代轮数：0，噪声率：0.5464%\n",
      "迭代轮数：1，噪声率：0.4675%\n",
      "迭代轮数：2，噪声率：0.4443%\n",
      "迭代轮数：3，噪声率：0.4357%\n",
      "迭代轮数：4，噪声率：0.4332%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置超参数\n",
    "alpha = 1.0  # 直接邻居的权重\n",
    "beta = 1.0\n",
    "max_iter = 5\n",
    "\n",
    "# 定义两种邻居方向组合\n",
    "neighbors_set1 = [(1, 0), (-1, 0), (0, 1), (0, -1)]  # 四个直接邻居\n",
    "neighbors_set2 = [(0, 1), (1, 0), (-1, 0)]  # 三个直接邻居（缺少一个方向）\n",
    "\n",
    "# 为每种邻居方向组合设置不同的 alpha_diag\n",
    "alpha_diag_set1 = 0.5 * alpha  # 对角线邻居的权重\n",
    "alpha_diag_set2 = 0.5 * alpha\n",
    "\n",
    "# 处理第一种邻居方向组合\n",
    "print(\"邻居方向组合：[(1, 0), (-1, 0), (0, 1), (0, -1)]\")\n",
    "X = np.copy(noisy_img)\n",
    "for k in range(max_iter):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X[i, j] = 1\n",
    "            pos_energy = compute_energy(X, noisy_img, i, j, alpha, alpha_diag_set1, beta)\n",
    "            X[i, j] = -1\n",
    "            neg_energy = compute_energy(X, noisy_img, i, j, alpha, alpha_diag_set1, beta)\n",
    "            X[i, j] = 1 if pos_energy < neg_energy else -1\n",
    "    noise_rate = compute_noise_rate(X, orig_img) * 100\n",
    "    print(f'迭代轮数：{k}，噪声率：{noise_rate:.4f}%')\n",
    "\n",
    "# 处理第二种邻居方向组合\n",
    "print(\"\\n邻居方向组合：[(0, 1), (1, 0), (-1, 0)]\")\n",
    "X = np.copy(noisy_img)\n",
    "for k in range(max_iter):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X[i, j] = 1\n",
    "            pos_energy = compute_energy(X, noisy_img, i, j, alpha, alpha_diag_set2, beta)\n",
    "            X[i, j] = -1\n",
    "            neg_energy = compute_energy(X, noisy_img, i, j, alpha, alpha_diag_set2, beta)\n",
    "            X[i, j] = 1 if pos_energy < neg_energy else -1\n",
    "    noise_rate = compute_noise_rate(X, orig_img) * 100\n",
    "    print(f'迭代轮数：{k}，噪声率：{noise_rate:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "带噪图像与原图不一致的像素比例：9.9386%  \n",
    "- [(1, 0), (-1, 0), (0, 1), (0, -1)]  \n",
    "迭代轮数：0，噪声率：0.5464%  \n",
    "迭代轮数：1，噪声率：0.4675%  \n",
    "迭代轮数：2，噪声率：0.4443%  \n",
    "迭代轮数：3，噪声率：0.4357%  \n",
    "迭代轮数：4，噪声率：0.4332%  \n",
    "- [(0, 1), (1, 0), (-1, 0)]    \n",
    "迭代轮数：0，噪声率：0.4293%  \n",
    "迭代轮数：1，噪声率：0.3064%  \n",
    "迭代轮数：2，噪声率：0.2782%  \n",
    "迭代轮数：3，噪声率：0.2746%  \n",
    "迭代轮数：4，噪声率：0.2732% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题6\n",
    " 在20 newsgroups数据集中，各个新闻事实上还包含了标题、脚注、引用等信息，而这些信息常常含有大量提示主题的关键词。因此，是否包含这些信息对分类准确率的影响非常大。阅读文档，在`fetch_20newsgroups_vectorized`函数中添加`remove`参数，把相关的主题信息移除，观察分类准确率的变化。在现实场景中，我们是否能获取到这些信息？这提示我们在利用机器学习完成实际中的任务时要注意什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率（保留header后分类准确率）: 0.9265\n",
      "准确率（移除header后分类准确率）: 0.7578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 加载数据（保留所有信息）\n",
    "data_raw = fetch_20newsgroups(subset='all', remove=())\n",
    "X_raw, y_raw = data_raw.data, data_raw.target\n",
    "\n",
    "# 加载数据（移除标题、脚注、引用）\n",
    "data_clean = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "X_clean, y_clean = data_clean.data, data_clean.target\n",
    "\n",
    "# 分割数据集\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建模型（TF-IDF + 线性SVM）\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "\n",
    "# 训练并评估原始数据\n",
    "model.fit(X_train_raw, y_train_raw)\n",
    "pred_raw = model.predict(X_test_raw)\n",
    "acc_raw = accuracy_score(y_test_raw, pred_raw)\n",
    "print(f\"准确率（保留header后分类准确率）: {acc_raw:.4f}\")\n",
    "\n",
    "# 训练并评估移除后的数据\n",
    "model.fit(X_train_clean, y_train_clean)\n",
    "pred_clean = model.predict(X_test_clean)\n",
    "acc_clean = accuracy_score(y_test_clean, pred_clean)\n",
    "print(f\"准确率（移除header后分类准确率）: {acc_clean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现移除后分类准确率降低了。  \n",
    "\\\n",
    "在现实场景中，进行新闻分类任务，我们可能会获得全面的新闻数据，也可能获取的是被处理过的缺少此类主题相关信息，只包含正文的数据。  \n",
    "\\\n",
    "这提示我们在使用机器学习完成实际任务时，数据信息的完整性会对任务效果产生影响，要注意去**理解数据的构成和特性，做合适的数据预处理，根据数据去设计合适的算法模型**。对于一些数据，因为隐私和合规性问题，我们确实需要对数据进行处理，损失一些信息也是必要的。\n",
    "\n",
    "[sklearn.datasets.fetch_20newsgroups_vectorized](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html)  \n",
    "\n",
    ">removetuple, default=()  \n",
    "May contain any subset of (‘headers’, ‘footers’, ‘quotes’). Each of these are kinds of text that will be detected and removed from the newsgroup posts, preventing classifiers from overfitting on metadata.  \n",
    "‘headers’ removes newsgroup headers, ‘footers’ removes blocks at the ends of posts that look like signatures, and ‘quotes’ removes lines that appear to be quoting another post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
